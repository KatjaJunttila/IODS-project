# Logistic regression

In this exercise, we are using a modified data set about student alcohol consumption. The original data can be found here: https://archive.ics.uci.edu/ml/datasets/Student+Performance. The data is from this study:

- P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.

```{r}
alc <- read.csv("data/alc.csv")
variable.names(alc)
```

Here are the variable names in the alc data set. The data includes measures of student achievement collected from school reports and questionnaires. The original data set consisted of two sets: performance in mathematics and performance in Portuguese language. The alc dataset is a combbination of those two original ones. I have created the variables alc_use and high_use. Alc_use is the average of weekday and weekend alcohol consumption and high_use is a logical variable which is true if alc_use is greater than 2.

I'm going to study relationship between alcohol consumption and:

- weekly study time
- current health status
- absences from school
- final grade

Here are my hypotheses:

- Students whose alcohol consumption is high use less time studying.
- High alcohol consumption is related to lower health status.
- High alcohol consumption is related to more absences from school.
- High alcohol consumption is related to lower final grade.

I'll examine the distributions of the selected variables with box plots.

```{r}
library(ggplot2)
gstudy <- ggplot(alc, aes(x = high_use, y = studytime))
gstudy + geom_boxplot() + ylab("weekly study time")
```

By looking at the boxplot, it seems that weekly study time is lower for the students whose alcohol consumption is high, as expected.

```{r}
ghealth <- ggplot(alc, aes(x = high_use, y = health))
ghealth + geom_boxplot() + ylab("current health status")
```

Contrary to my hypothesis, it seems that there is no difference in current health status between students whose alcohol consumption id high and other students.

```{r}
gabsent <- ggplot(alc, aes(x = high_use, y = absences))
gabsent + geom_boxplot() + ylab("number of school absences")
```

The boxplot shows there are some outliers in both groups. It still seems that students whose alcohol consumption is high are absent from school more often, as hypothesised.

```{r}
ggrade <- ggplot(alc, aes(x = high_use, y = G3))
ggrade + geom_boxplot() + ylab("final grade")
```

This boxplot shows again some outliers. It appears that the final grades may be lower in the high alcohol consumption group, as expected.

Weekly study time and current health status are categorical variables. I'll examine them by cross-tabulation with high alcohol use.
```{r}
table(high_use = alc$high_use, study_time = alc$studytime)
```
Here's the cross table for weekly study time. This further substantiates that high alcohol consumption is related to studying less: there are few students who consume a lot of alcohol in the two categories with the highest study times.

```{r}
table(high_use = alc$high_use, health = alc$health)
```
As the boxplot already showed, the distributions of current health do not look that different between the groups.

Next, I'm fitting a logistic regression model with the `high_use` as the target variable and `studytime`, `health`, `absences`, and `G3` as the predictors. `Studytime` and `health`are factors.
```{r}
m <- glm(high_use ~ factor(studytime) + factor(health) + absences + G3, data = alc, family = "binomial")
summary(m)
```
Above is the summary of the fitted model. We can see that there is a significant difference between the coefficients of `studytime1` and `studytime3`as well as between `studytime1`and `studytime4`. No significant differences between current health levels are observed. There is a significant relationship between absences and high alcohol consumption, but no relationship is observed between final grade and high alcohol consumption, unlike hypothesised. Based on the model and previous distribution examination, I'll fit the model again without `health`and `G3`. This time I'll also fit the model without an intercept to see the coefficients of different `studytimes` directly.
```{r}
m <- glm(high_use ~ factor(studytime) + absences -1, data = alc, family = "binomial")
summary(m)
```
This time all coefficients are significant. The smaller Akaike information criterion (AIC) indicates a better fit of this model.

Let's create odds ratios and confidence intervals.
```{r}
library("dplyr")
OR <- coef(m) %>% exp
CI <- confint(m) %>% exp
cbind(OR, CI)
```
Here we can see that none of the confidence intervals includes 1, which means that they are all significant. Odds ratios for `studytime` show that students who study less are more likely to be high alcohol consumers than students who spend more time studying. Absences from school also indicate higher odds of high alcohol consumption. These findings are in accordance with my hypotheses.

Next, I'll investigate the model's predictive power by forming a cross table of predictions versus the actual values.
```{r}
probabilities <- predict(m, type = "response")
alc <- mutate(alc, probability = probabilities)
alc <- mutate(alc, prediction = probability > 0.5)
table(high_use = alc$high_use, prediction = alc$prediction)
```
This table shows that 258 of the students who are not high alcohol consumers and 15 of the students who are high alcohol consumers are correctly classified by my model. Ten of the low alcohol consumers are falsely classified as high consumers and 99 of high consumers are falsely classified as low consumers.

Here is the same information as proportions:
```{r}
table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table %>% addmargins
```

Below is a visualisation of the high use versus probability.
```{r}
g <- ggplot(alc, aes(x = probability, y = high_use, col = prediction))
g + geom_point()
```
```{r}
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}
loss_func(class = alc$high_use, prob = alc$probability)
```
The total proportion of inaccurately classified students is approximately 28.5%.

Here I'll perform 10-fold cross-validation on my model:
```{r}
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}
loss_func(class = alc$high_use, prob = alc$probability)
library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)
cv$delta[1]
```
My model has poorer test set performance (prediction error 0.29) compared to the model introduced in DataCamp (0.26).

